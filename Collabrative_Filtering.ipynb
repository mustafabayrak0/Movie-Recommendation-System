{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67a0a2c0-cb57-42af-962e-ed3e2a426777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935af23f-2ef3-406b-92ca-fb9b48a2500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CollaborativeFilteringModel:\n",
    "    def __init__(self, ratings_file, movies_file):\n",
    "        self.ratings_file = ratings_file\n",
    "        self.movies_file = movies_file\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.movie_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load the dataset\n",
    "        ratings = pd.read_csv(self.ratings_file)\n",
    "        movies = pd.read_csv(self.movies_file)\n",
    "\n",
    "        # Merge ratings and movies data\n",
    "        data = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "        # Encode user and movie IDs\n",
    "        data['user'] = self.user_encoder.fit_transform(data['userId'].values)\n",
    "        data['movie'] = self.movie_encoder.fit_transform(data['movieId'].values)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def create_model(self, num_users, num_movies, embedding_size=50):\n",
    "        user_input = Input(shape=(1,), name='user_input')\n",
    "        movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "        user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, input_length=1)(user_input)\n",
    "        movie_embedding = Embedding(input_dim=num_movies, output_dim=embedding_size, input_length=1)(movie_input)\n",
    "\n",
    "        user_flatten = Flatten()(user_embedding)\n",
    "        movie_flatten = Flatten()(movie_embedding)\n",
    "\n",
    "        merged = Concatenate()([user_flatten, movie_flatten])\n",
    "        dense1 = Dense(4, activation='tanh')(merged)\n",
    "        output = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "        model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(lr=0.00001), loss='mean_squared_error')\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train_model(self, data, epochs=5, batch_size=64, validation_split=0.2):\n",
    "        # Split the data into training and testing sets\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Get the number of unique users and movies\n",
    "        num_users = data['user'].nunique()\n",
    "        num_movies = data['movie'].nunique()\n",
    "\n",
    "        # Create and train the model\n",
    "        self.model = self.create_model(num_users, num_movies)\n",
    "        self.model.fit([train_data['user'], train_data['movie']], train_data['rating'],\n",
    "                       epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def evaluate_model(self, test_data, threshold=0.55):\n",
    "        # Evaluate the model\n",
    "        eval_result = self.model.evaluate([test_data['user'], test_data['movie']], test_data['rating'])\n",
    "        print(\"Evaluation Result - Loss: {:.4f}\".format(eval_result))\n",
    "\n",
    "        # Predict ratings on the test data\n",
    "        predictions = self.model.predict([test_data['user'], test_data['movie']])\n",
    "\n",
    "        # Convert predictions to binary values (0 or 1) based on the threshold\n",
    "        binary_predictions = (predictions >= threshold).astype(int)\n",
    "\n",
    "        # Create an \"is_liked\" column based on the rating threshold\n",
    "        test_data[\"is_liked\"] = np.where(test_data['rating'] >= 3.5, 1, 0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = sum((binary_predictions == test_data['is_liked'].values.reshape(-1, 1)).all(axis=1)) / len(test_data)\n",
    "        print(\"Accuracy: {:.2%}\".format(accuracy))\n",
    "\n",
    "    def recommend_movies(self, user_id, model_file='collabrative_filtering_model.h5', top_n=10):\n",
    "        # Load the saved model\n",
    "        model = load_model(model_file)\n",
    "\n",
    "        # Load the full dataset\n",
    "        data = self.load_data()\n",
    "\n",
    "        # Check if the user_id is in the dataset\n",
    "        if user_id not in data['userId'].unique():\n",
    "            print(\"User ID not found in the dataset.\")\n",
    "            return\n",
    "\n",
    "        # Filter data for the given user ID\n",
    "        user_data = data[data['userId'] == user_id]\n",
    "\n",
    "        # Encode the given user ID\n",
    "        encoded_user_id = self.user_encoder.transform([user_id])\n",
    "\n",
    "        # Get all unique movie IDs from the dataset and encode them\n",
    "        all_movies = data['movieId'].unique()\n",
    "        encoded_movies = self.movie_encoder.transform(all_movies)\n",
    "\n",
    "        # Predict ratings for all movies for this user\n",
    "        predicted_ratings = model.predict([np.array([encoded_user_id[0]] * len(all_movies)), encoded_movies])\n",
    "\n",
    "        # Create a DataFrame with movie IDs and their predicted ratings\n",
    "        movie_ratings = pd.DataFrame({\n",
    "            'movieId': all_movies,\n",
    "            'predicted_rating': predicted_ratings.flatten()\n",
    "        })\n",
    "\n",
    "        # Exclude movies that the user has already rated\n",
    "        rated_movies = user_data['movieId'].unique()\n",
    "        recommendations = movie_ratings[~movie_ratings['movieId'].isin(rated_movies)]\n",
    "\n",
    "        # Sort the movies based on predicted ratings and select the top N\n",
    "        top_recommendations = recommendations.sort_values(by='predicted_rating', ascending=False).head(top_n)\n",
    "\n",
    "        # Translate back to movie titles\n",
    "        movies_df = pd.read_csv(self.movies_file)\n",
    "        top_recommendations = top_recommendations.merge(movies_df, on='movieId')\n",
    "\n",
    "        return top_recommendations[['movieId', 'title', 'predicted_rating']]\n",
    "\n",
    "\n",
    "    def save_model(self, model_file='collabrative_filtering_model.h5'):\n",
    "        # Save the model\n",
    "        self.model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb23e29-ac2c-40d8-a6f7-c50009e4890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbber\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009/1009 [==============================] - 6s 5ms/step - loss: 10.0396 - val_loss: 10.0377\n",
      "Epoch 2/5\n",
      "1009/1009 [==============================] - 5s 5ms/step - loss: 9.9272 - val_loss: 9.9145\n",
      "Epoch 3/5\n",
      "1009/1009 [==============================] - 6s 5ms/step - loss: 9.7920 - val_loss: 9.7676\n",
      "Epoch 4/5\n",
      "1009/1009 [==============================] - 6s 6ms/step - loss: 9.6352 - val_loss: 9.6022\n",
      "Epoch 5/5\n",
      "1009/1009 [==============================] - 7s 6ms/step - loss: 9.4633 - val_loss: 9.4252\n",
      "3152/3152 [==============================] - 5s 2ms/step - loss: 9.3819\n",
      "Evaluation Result - Loss: 9.3819\n",
      "3152/3152 [==============================] - 5s 1ms/step\n",
      "Accuracy: 61.09%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ratings_file = './ml-latest-small/ratings.csv'\n",
    "    movies_file = './ml-latest-small/movies.csv'\n",
    "\n",
    "    rec_system = CollaborativeFilteringModel(ratings_file, movies_file)\n",
    "    data = rec_system.load_data()\n",
    "    rec_system.train_model(data)\n",
    "    rec_system.evaluate_model(data)\n",
    "    rec_system.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e86a6-fd18-4748-957a-487a14dd05c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
